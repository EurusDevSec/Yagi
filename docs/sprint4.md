# üìÖ Sprint 4 Guide: The Interface & Resilience (Giao Di·ªán & Ch·ªãu L·ªói)

**M·ª•c ti√™u:** X√¢y d·ª±ng Dashboard theo d√µi b√£o th·ªùi gian th·ª±c v√† ki·ªÉm th·ª≠ kh·∫£ nƒÉng t·ª± ph·ª•c h·ªìi c·ªßa h·ªá th·ªëng.

---

## üìã Y√™u C·∫ßu Tr∆∞·ªõc Khi B·∫Øt ƒê·∫ßu

- ‚úÖ Ho√†n th√†nh Sprint 3 (Predictor Service ƒë√£ ch·∫°y ·ªïn ƒë·ªãnh).
- ‚úÖ Docker containers ƒëang ch·∫°y (`kafka`, `predictor`, v.v.).

---

## 1. X√¢y D·ª±ng Dashboard (Streamlit)

Ch√∫ng ta s·∫Ω t·∫°o m·ªôt service m·ªõi t√™n l√† `dashboard` ƒë·ªÉ hi·ªÉn th·ªã d·ªØ li·ªáu t·ª´ Kafka l√™n bi·ªÉu ƒë·ªì.

### B∆∞·ªõc 1.1: T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c

T·∫°i th∆∞ m·ª•c g·ªëc d·ª± √°n, t·∫°o th∆∞ m·ª•c `dashboard`:

```bash
mkdir dashboard
```

### B∆∞·ªõc 1.2: T·∫°o file `dashboard/requirements.txt`

```text
streamlit
kafka-python
pandas
altair
watchdog
```

### B∆∞·ªõc 1.3: T·∫°o file `dashboard/Dockerfile`

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.address=0.0.0.0"]
```

### B∆∞·ªõc 1.4: T·∫°o file `dashboard/app.py`

ƒê√¢y l√† tr√°i tim c·ªßa giao di·ªán. N√≥ s·∫Ω ƒë·ªçc d·ªØ li·ªáu t·ª´ Kafka topic `weather-stream` v√† `storm-alerts` ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.

```python
import streamlit as st
import pandas as pd
import json
from kafka import KafkaConsumer
import time
from datetime import datetime

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="YAGI Storm Monitor",
    page_icon="üå™Ô∏è",
    layout="wide"
)

# Ti√™u ƒë·ªÅ
st.title("üå™Ô∏è YAGI Storm Real-time Monitor")
st.markdown("H·ªá th·ªëng gi√°m s√°t v√† c·∫£nh b√°o b√£o th·ªùi gian th·ª±c")

# C·∫•u h√¨nh Kafka
KAFKA_BOOTSTRAP_SERVERS = 'yagi-kafka:9092'
TOPIC_WEATHER = 'weather-stream'
TOPIC_ALERTS = 'storm-alerts'

# H√†m nh·∫≠n d·ªØ li·ªáu t·ª´ Kafka (gi·∫£ l·∫≠p polling ƒë·ªÉ kh√¥ng block UI)
# L∆∞u √Ω: Streamlit ho·∫°t ƒë·ªông theo c∆° ch·∫ø rerun, n√™n vi·ªác t√≠ch h·ª£p Kafka consumer tr·ª±c ti·∫øp
# c·∫ßn kh√©o l√©o. ·ªû ƒë√¢y ta d√πng placeholder ƒë·ªÉ update.

# T·∫°o c√°c placeholder cho UI
col1, col2, col3 = st.columns(3)
with col1:
    metric_wind = st.empty()
with col2:
    metric_pressure = st.empty()
with col3:
    metric_status = st.empty()

st.divider()

col_chart_1, col_chart_2 = st.columns(2)
with col_chart_1:
    st.subheader("T·ªëc ƒë·ªô gi√≥ (km/h)")
    chart_wind = st.line_chart(x=None, y=None, height=300)

with col_chart_2:
    st.subheader("√Åp su·∫•t kh√≠ quy·ªÉn (mb)")
    chart_pressure = st.line_chart(x=None, y=None, height=300)

st.subheader("üö® Nh·∫≠t k√Ω C·∫£nh b√°o")
alert_log = st.empty()

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u d·ªØ li·ªáu
if 'data' not in st.session_state:
    st.session_state.data = pd.DataFrame(columns=['timestamp', 'windspeed', 'pressure'])
if 'alerts' not in st.session_state:
    st.session_state.alerts = []

def consume_data():
    consumer = KafkaConsumer(
        TOPIC_WEATHER,
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        value_deserializer=lambda m: json.loads(m.decode('utf-8')),
        auto_offset_reset='latest', # Ch·ªâ ƒë·ªçc d·ªØ li·ªáu m·ªõi nh·∫•t
        group_id='dashboard-group-v1',
        consumer_timeout_ms=100 # Kh√¥ng ch·ªù qu√° l√¢u
    )

    # L·∫•y d·ªØ li·ªáu m·ªõi
    new_rows = []
    for message in consumer:
        record = message.value
        timestamp = record.get('datetime')
        wind = record.get('windspeed', 0)
        pressure = record.get('sealevelpressure', 0)

        new_rows.append({
            'timestamp': timestamp,
            'windspeed': wind,
            'pressure': pressure
        })

        # Update Metrics ngay l·∫≠p t·ª©c
        metric_wind.metric("Gi√≥", f"{wind} km/h", delta_color="inverse")
        metric_pressure.metric("√Åp su·∫•t", f"{pressure} mb")

        if wind > 60:
            metric_status.error("‚ö†Ô∏è NGUY HI·ªÇM")
        else:
            metric_status.success("‚úÖ AN TO√ÄN")

    # C·∫≠p nh·∫≠t DataFrame
    if new_rows:
        new_df = pd.DataFrame(new_rows)
        st.session_state.data = pd.concat([st.session_state.data, new_df], ignore_index=True).tail(100) # Gi·ªØ 100 ƒëi·ªÉm d·ªØ li·ªáu cu·ªëi

        # V·∫Ω l·∫°i bi·ªÉu ƒë·ªì
        chart_wind.line_chart(st.session_state.data.set_index('timestamp')['windspeed'])
        chart_pressure.line_chart(st.session_state.data.set_index('timestamp')['pressure'])

# N√∫t ƒë·ªÉ ch·∫°y (Streamlit t·ª± ƒë·ªông rerun nh∆∞ng ta c·∫ßn v√≤ng l·∫∑p cho Kafka)
if st.button('B·∫Øt ƒë·∫ßu gi√°m s√°t'):
    st.success("ƒêang k·∫øt n·ªëi Kafka...")
    while True:
        consume_data()
        time.sleep(1)
```

### B∆∞·ªõc 1.5: C·∫≠p nh·∫≠t `docker-compose.yaml`

Th√™m service `dashboard` v√†o file `docker-compose.yaml`:

```yaml
# ... (c√°c service c≈©)

# --- Visualization ---
dashboard:
  build: ./dashboard
  container_name: yagi-dashboard
  ports:
    - "8501:8501"
  depends_on:
    - kafka
  restart: always
```

### B∆∞·ªõc 1.6: Ch·∫°y Dashboard

1.  Build v√† ch·∫°y container:
    ```bash
    docker-compose up -d --build dashboard
    ```
2.  Truy c·∫≠p tr√¨nh duy·ªát: `http://localhost:8501`
3.  Nh·∫•n n√∫t **"B·∫Øt ƒë·∫ßu gi√°m s√°t"**.
4.  Ch·∫°y `python jobs/yagi_producer.py` ·ªü terminal kh√°c ƒë·ªÉ b∆°m d·ªØ li·ªáu v√† xem bi·ªÉu ƒë·ªì nh·∫£y m√∫a!

---

## 2. T√≠ch h·ª£p Telegram Alert (N√¢ng cao)

ƒê·ªÉ nh·∫≠n tin nh·∫Øn c·∫£nh b√°o v·ªÅ ƒëi·ªán tho·∫°i.

### B∆∞·ªõc 2.1: T·∫°o Bot Telegram

1.  Chat v·ªõi **@BotFather** tr√™n Telegram.
2.  G√µ `/newbot` -> ƒê·∫∑t t√™n -> Nh·∫≠n **TOKEN**.
3.  T·∫°o m·ªôt group chat, add con bot v√†o.
4.  L·∫•y **Chat ID** c·ªßa group (c√≥ th·ªÉ d√πng @userinfobot ho·∫∑c xem API).

### B∆∞·ªõc 2.2: C·∫≠p nh·∫≠t `predictor/predictor.py`

Th√™m h√†m g·ª≠i Telegram:

```python
import requests

TELEGRAM_TOKEN = "YOUR_TOKEN_HERE"
TELEGRAM_CHAT_ID = "YOUR_CHAT_ID_HERE"

def send_telegram_alert(message):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message,
        "parse_mode": "Markdown"
    }
    try:
        requests.post(url, json=payload)
    except Exception as e:
        print(f"Failed to send Telegram: {e}")

# ... Trong v√≤ng l·∫∑p x·ª≠ l√Ω, ch·ªó t·∫°o alert:
if prediction == 1:
    msg = f"üö® **C·∫¢NH B√ÅO B√ÉO YAGI**\n\nTh·ªùi gian: {record['datetime']}\nGi√≥: {record['windspeed']} km/h\nC·∫•p ƒë·ªô: NGUY HI·ªÇM"
    send_telegram_alert(msg)
```

---

## 3. Chaos Engineering (Ki·ªÉm th·ª≠ ch·ªãu l·ªói)

M·ª•c ti√™u: Ch·ª©ng minh h·ªá th·ªëng kh√¥ng ch·∫øt khi m·ªôt th√†nh ph·∫ßn b·ªã l·ªói.

### K·ªãch b·∫£n: "S√°t th·ªß" Predictor

1.  ƒê·∫£m b·∫£o h·ªá th·ªëng ƒëang ch·∫°y, Dashboard ƒëang hi·ªÉn th·ªã, Producer ƒëang b·∫Øn tin.
2.  M·ªü terminal, gi·∫øt ch·∫øt container `predictor`:
    ```bash
    docker kill yagi-predictor
    ```
3.  Quan s√°t:
    - Dashboard: V·∫´n hi·ªÉn th·ªã d·ªØ li·ªáu c≈©, kh√¥ng b·ªã crash.
    - Docker: V√¨ ta ƒë·ªÉ `restart: on-failure` (ho·∫∑c `always`), Docker s·∫Ω t·ª± ƒë·ªông kh·ªüi ƒë·ªông l·∫°i `predictor`.
4.  Ki·ªÉm tra log:
    ```bash
    docker logs -f yagi-predictor
    ```
    - Th·∫•y service kh·ªüi ƒë·ªông l·∫°i, k·∫øt n·ªëi l·∫°i Kafka v√† ti·∫øp t·ª•c x·ª≠ l√Ω.

---

## üéâ T·ªïng K·∫øt D·ª± √Ån

B·∫°n ƒë√£ ho√†n th√†nh x√¢y d·ª±ng h·ªá th·ªëng **Y.A.G.I** End-to-End:

1.  **Ingestion:** Kafka KRaft nh·∫≠n d·ªØ li·ªáu t·ªëc ƒë·ªô cao.
2.  **Storage:** MinIO l∆∞u tr·ªØ Data Lake.
3.  **Processing:** Spark x·ª≠ l√Ω d·ªØ li·ªáu.
4.  **Intelligence:** Predictor Service d·ª± b√°o b√£o b·∫±ng AI.
5.  **Visualization:** Dashboard theo d√µi th·ªùi gian th·ª±c.
6.  **Resilience:** H·ªá th·ªëng t·ª± ph·ª•c h·ªìi sau s·ª± c·ªë.
