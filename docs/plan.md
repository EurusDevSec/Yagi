

---

# ðŸŒªï¸ PROJECT C.H.A.O.S
**(Climate Hazard Analysis & Operations System)**

### 1. TÃªn Äá» TÃ i & Äá»‹nh Vá»‹
* **TÃªn chÃ­nh thá»©c (BÃ¡o cÃ¡o):** XÃ¢y dá»±ng Há»‡ thá»‘ng Data Lakehouse & MLOps End-to-End cho Cáº£nh bÃ¡o Biáº¿n Ä‘á»•i KhÃ­ háº­u Thá»i gian thá»±c.
* **TÃªn mÃ£ (Codename):** Project C.H.A.O.S.
* **Slogan:** *"Biáº¿n sá»± há»—n loáº¡n cá»§a dá»¯ liá»‡u thÃ nh tráº­t tá»± cá»§a dá»± bÃ¡o."*
* **Äá»‹nh vá»‹:** Má»™t há»‡ thá»‘ng Big Data hiá»‡n Ä‘áº¡i (SOTA), tÃ­ch há»£p tÆ° duy DevOps/System Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n khÃ­ háº­u, vÆ°á»£t xa cÃ¡c Ä‘á»“ Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u tÄ©nh thÃ´ng thÆ°á»ng.

### 2. Má»¥c TiÃªu Dá»± Ãn (Objectives)
* **Má»¥c tiÃªu cá»‘t lÃµi (Core):** XÃ¢y dá»±ng thÃ nh cÃ´ng Pipeline xá»­ lÃ½ dá»¯ liá»‡u lá»›n tá»« khÃ¢u thu tháº­p (Ingestion) -> lÆ°u trá»¯ (Storage) -> xá»­ lÃ½ (Processing) -> dá»± bÃ¡o (Prediction) theo thá»i gian thá»±c (Real-time).
* **Má»¥c tiÃªu cÃ´ng nghá»‡ (Tech):**
    * [cite_start]Triá»ƒn khai kiáº¿n trÃºc **Data Lakehouse** (MinIO + Delta Lake)[cite: 7, 13].
    * [cite_start]á»¨ng dá»¥ng **Apache Spark Streaming** cho xá»­ lÃ½ luá»“ng[cite: 10, 46].
    * [cite_start]Thiáº¿t láº­p quy trÃ¬nh **MLOps cÆ¡ báº£n** (Train trÃªn Cloud, Deploy dÆ°á»›i Edge)[cite: 79].
    * Chá»©ng minh kháº£ nÄƒng chá»‹u lá»—i (Resilience) thÃ´ng qua **Chaos Engineering**.
* **Má»¥c tiÃªu Ä‘áº§u ra (Deliverable):** Má»™t há»‡ thá»‘ng cháº¡y Ä‘Æ°á»£c trÃªn Docker Compose, cÃ³ Dashboard Real-time hiá»ƒn thá»‹ dá»¯ liá»‡u khÃ­ háº­u vÃ  cáº£nh bÃ¡o thiÃªn tai.

### 3. Kiáº¿n TrÃºc Ká»¹ Thuáº­t (Hybrid Architecture - 16GB RAM Optimized)

* **Ingestion Layer:**
    * *Source:* Dá»¯ liá»‡u lá»‹ch sá»­ Kaggle (Hourly Weather Data) giáº£ láº­p luá»“ng Real-time (Data Replay).
    * *Message Queue:* **Apache Kafka** (Image: `bitnami/kafka`, KRaft Mode - No Zookeeper).
* **Storage Layer (Data Lakehouse):**
    * [cite_start]*Object Storage:* **MinIO** (Giáº£ láº­p S3)[cite: 15].
    * [cite_start]*Table Format:* **Delta Lake** (Há»— trá»£ ACID & Time-travel)[cite: 7, 15].
* **Processing Layer:**
    * [cite_start]*Engine:* **Apache Spark (PySpark)** cháº¡y cháº¿ Ä‘á»™ Streaming[cite: 5].
* **Intelligence Layer (MLOps):**
    * [cite_start]*Training:* **Google Colab** (Sá»­ dá»¥ng Spark MLlib Ä‘á»ƒ train model dá»± bÃ¡o)[cite: 5].
    * *Serving:* Python Script load model Ä‘Ã£ train Ä‘á»ƒ dá»± bÃ¡o realtime.
* **Presentation Layer:**
    * *Dashboard:* **Streamlit** (Python).
    * *Alerting:* Telegram Bot (Optional).
* **Infrastructure:**
    * **Docker Compose** Ä‘á»ƒ quáº£n lÃ½ toÃ n bá»™ service.
    * **Monitoring:** **Portainer** (Container Management UI).

---

### 4. Káº¿ Hoáº¡ch Thá»±c Hiá»‡n Chi Tiáº¿t (4-Week Agile Sprint)

#### ðŸ“… Sprint 1: The Foundation - XÃ¢y Dá»±ng Háº¡ Táº§ng Container
* **Má»¥c tiÃªu:** Dá»±ng xong cá»¥m Cluster áº£o trÃªn mÃ¡y local. Lá»‡nh `docker-compose up` pháº£i cháº¡y mÆ°á»£t mÃ , khÃ´ng sáº­p nguá»“n vÃ¬ thiáº¿u RAM.
* **CÃ´ng viá»‡c cá»¥ thá»ƒ:**
    1.  CÃ i Ä‘áº·t mÃ´i trÆ°á»ng: Docker Desktop, Python 3.9+, Java (náº¿u cáº§n debug).
    2.  Thiáº¿t káº¿ file `docker-compose.yaml`:
        * Cáº¥u hÃ¬nh **Kafka (KRaft Mode)**: Loáº¡i bá» Zookeeper giÃºp tiáº¿t kiá»‡m ~500MB-1GB RAM.
        * Cáº¥u hÃ¬nh **Portainer**: ThÃªm container Portainer Ä‘á»ƒ monitoring trá»±c quan.
        * Cáº¥u hÃ¬nh **MinIO**: Thiáº¿t láº­p Access Key/Secret Key, táº¡o sáºµn Bucket `climate-data`.
        * Cáº¥u hÃ¬nh **Spark Master & Worker**: Giá»›i háº¡n Worker RAM tá»‘i Ä‘a 4GB.
    3.  Kiá»ƒm thá»­ (Smoke Test):
        * DÃ¹ng Kafka Tool káº¿t ná»‘i port 9092.
        * Truy cáº­p MinIO Console (localhost:9001).
        * Truy cáº­p Spark UI (localhost:8080).

#### ðŸ“… Sprint 2: The Flow - DÃ²ng Cháº£y Dá»¯ Liá»‡u "Data Replay"
* **Má»¥c tiÃªu:** Dá»¯ liá»‡u tá»« file Kaggle pháº£i "cháº£y" vÃ o MinIO dÆ°á»›i dáº¡ng Delta Lake theo thá»i gian thá»±c.
* **CÃ´ng viá»‡c cá»¥ thá»ƒ:**
    1.  Chuáº©n bá»‹ dá»¯ liá»‡u: Táº£i dataset **"Hourly Weather Data"** tá»« Kaggle.
    2.  Viáº¿t `replay_producer.py`:
        * Äá»c tuáº§n tá»± tá»«ng dÃ²ng CSV.
        * Thay tháº¿ timestamp cÅ© báº±ng `datetime.now()`.
        * Äáº©y vÃ o Kafka Topic `weather-realtime`.
    3.  Viáº¿t `ingestion_job.py` (Spark Streaming):
        * Äá»c tá»« Kafka `weather-realtime`.
        * Parse JSON/CSV.
        * Ghi xuá»‘ng MinIO bucket `climate-data` Ä‘á»‹nh dáº¡ng **Delta Lake**.
    4.  Kiá»ƒm chá»©ng: Tháº¥y file `.parquet` sinh ra liÃªn tá»¥c trong MinIO.

#### ðŸ“… Sprint 3: The Brain - TrÃ­ Tuá»‡ Lai (Hybrid MLOps)
* **Má»¥c tiÃªu:** Train model trÃªn Cloud (Colab) vÃ  mang vá» Local deploy.
* **CÃ´ng viá»‡c cá»¥ thá»ƒ:**
    1.  Xuáº¥t dá»¯ liá»‡u: Copy má»™t lÆ°á»£ng dá»¯ liá»‡u lá»‹ch sá»­ tá»« MinIO (hoáº·c dÃ¹ng chÃ­nh file Kaggle gá»‘c) upload lÃªn Google Drive.
    2.  Training trÃªn Colab:
        * DÃ¹ng **PySpark MLlib**.
        * BÃ i toÃ¡n: Dá»± bÃ¡o nhiá»‡t Ä‘á»™ giá» tiáº¿p theo (Regression) hoáº·c PhÃ¢n loáº¡i rá»§i ro bÃ£o (Classification).
        * Export model Ä‘Ã£ train (`.zip` hoáº·c folder).
    3.  Deploy táº¡i Local (Inference Service):
        * Viáº¿t `prediction_service.py`.
        * Load model tá»« file Ä‘Ã£ táº£i vá».
        * Subscribe Kafka `weather-realtime` -> Predict -> Publish káº¿t quáº£ vÃ o Kafka `alert-data`.

#### ðŸ“… Sprint 4: The Face & The Chaos - Hiá»ƒn Thá»‹ & Kháº£ NÄƒng Chá»‹u Lá»—i
* **Má»¥c tiÃªu:** Dashboard Ä‘áº¹p, demo há»‡ thá»‘ng tá»± phá»¥c há»“i (Self-healing).
* **CÃ´ng viá»‡c cá»¥ thá»ƒ:**
    1.  XÃ¢y dá»±ng Dashboard (**Streamlit**):
        * Biá»ƒu Ä‘á»“ line chart: Nhiá»‡t Ä‘á»™ thá»±c táº¿ vs. Dá»± bÃ¡o.
        * Chá»‰ sá»‘ cáº£nh bÃ¡o: MÃ u Ä‘á» khi nhiá»‡t Ä‘á»™/Ä‘á»™ áº©m vÆ°á»£t ngÆ°á»¡ng.
    2.  Thá»±c hiá»‡n **Chaos Engineering**:
        * Cáº¥u hÃ¬nh Docker `restart: always`.
        * Viáº¿t script `chaos_monkey.py`: Random kill container `prediction_service`.
    3.  Tá»•ng diá»…n táº­p Demo:
        * Báº­t há»‡ thá»‘ng -> Cháº¡y Data Replay -> Show Dashboard.
        * Má»Ÿ **Portainer**: Quan sÃ¡t tráº¡ng thÃ¡i container.
        * Kill service (Chaos Monkey) -> Xem trÃªn Portainer tháº¥y container tá»± restart (Self-healing).

---

### 5. Tech Stack Chá»‘t Háº¡ (Tá»‘i Æ°u 16GB RAM)
* **Language:** Python (PySpark, Streamlit).
* **Big Data:** Apache Spark 3.x, Apache Kafka 3.x (KRaft Mode).
* **Storage:** MinIO, Delta Lake 2.x.
* **DevOps:** Docker, Docker Compose, Portainer.
* **Cloud:** Google Colab (cho Training).

