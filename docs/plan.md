# üå™Ô∏è PROJECT Y.A.G.I
**(Yielding Adaptive Geo-spatial Intelligence)**

> *"From the Storm that broke us, comes the Intelligence that saves us."*
> *(T·ª´ c∆°n b√£o t√†n ph√°, sinh ra tr√≠ tu·ªá b·∫£o v·ªá ch√∫ng ta.)*

---

### 1. T·ªîNG QUAN D·ª∞ √ÅN (Project Overview)

* **T√™n ƒë·ªÅ t√†i b√°o c√°o:** X√¢y d·ª±ng H·ªá th·ªëng Data Lakehouse & MLOps End-to-End cho C·∫£nh b√°o Thi√™n tai Th·ªùi gian th·ª±c (Case Study: Si√™u b√£o Yagi 2024).
* **M·ª•c ti√™u c·ªët l√µi:** T√°i hi·ªán l·∫°i c∆°n b√£o l·ªãch s·ª≠ Yagi d∆∞·ªõi d·∫°ng d·ªØ li·ªáu lu·ªìng (Streaming), qua ƒë√≥ ch·ª©ng minh kh·∫£ nƒÉng x·ª≠ l√Ω, l∆∞u tr·ªØ v√† c·∫£nh b√°o s·ªõm c·ªßa h·ªá th·ªëng Big Data hi·ªán ƒë·∫°i.
* **C√¥ng ngh·ªá ƒë·ªãnh h∆∞·ªõng:** Lambda Architecture, Data Lakehouse, MLOps, Containerization.

---

### 2. KI·∫æN TR√öC K·ª∏ THU·∫¨T (Technical Architecture)

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø theo m√¥ h√¨nh **Lambda Architecture** t·ªëi ∆∞u cho m√°y c·∫•u h√¨nh 16GB RAM:

#### üü¢ Layer 1: Ingestion (Thu th·∫≠p & Gi·∫£ l·∫≠p)
* **Data Source:** File `res/Hai phong, Viet Nam 2024-09-05 to 2024-09-09.csv`.
* **Technique:** **Data Replay**. Script Python ƒë·ªçc file CSV theo t·ª´ng d√≤ng, ƒë·∫©y v√†o h·ªá th·ªëng v·ªõi t·ªëc ƒë·ªô th·ª±c (ho·∫∑c x10 t·ªëc ƒë·ªô) ƒë·ªÉ gi·∫£ l·∫≠p c·∫£m bi·∫øn IoT ƒëang g·ª≠i d·ªØ li·ªáu b√£o v·ªÅ.
* **Message Queue:** **Apache Kafka (KRaft Mode)**. Lo·∫°i b·ªè Zookeeper ƒë·ªÉ ti·∫øt ki·ªám RAM. ƒê√≥ng vai tr√≤ v√πng ƒë·ªám (Buffer) ch·ªãu t·∫£i cao.

#### üîµ Layer 2: Speed Layer (X·ª≠ l√Ω N√≥ng - Real-time)
* **Engine:** **Apache Spark Streaming**.
* **Lu·ªìng x·ª≠ l√Ω:** ƒê·ªçc t·ª´ Kafka -> X·ª≠ l√Ω/L√†m s·∫°ch -> ƒê·∫©y th·∫≥ng sang **Prediction Service**.
* **Nhi·ªám v·ª•:** Ph√°t hi·ªán ngay l·∫≠p t·ª©c c√°c ch·ªâ s·ªë nguy hi·ªÉm (Gi√≥ > 100km/h, √Åp su·∫•t t·ª•t gi·∫£m).

#### üü£ Layer 3: Batch/Serving Layer (L∆∞u tr·ªØ & MLOps)
* **Data Lakehouse:** **MinIO (S3)** + **Delta Lake**.
    * L∆∞u tr·ªØ d·ªØ li·ªáu l·ªãch s·ª≠ b√£o Yagi b·ªÅn v·ªØng (ACID Transactions).
    * Ph·ª•c v·ª• truy v·∫•n l·ªãch s·ª≠ (Time Travel).
* **MLOps Training:** **Google Colab**.
    * L·∫•y d·ªØ li·ªáu t·ª´ Lakehouse -> Train model d·ª± b√°o b√£o -> ƒê√≥ng g√≥i Model.
* **Inference:** **Docker Container** ch·∫°y model ƒë√£ train, nh·∫≠n d·ªØ li·ªáu n√≥ng t·ª´ Kafka ƒë·ªÉ ƒë∆∞a ra c·∫£nh b√°o.

#### üü† Layer 4: Visualization (Hi·ªÉn th·ªã)
* **Dashboard:** **Streamlit**. V·∫Ω bi·ªÉu ƒë·ªì di·ªÖn bi·∫øn b√£o Real-time.
* **Alert:** **Telegram Bot**. B·∫Øn tin nh·∫Øn c·∫£nh b√°o kh·∫©n c·∫•p t·ªõi ƒëi·ªán tho·∫°i.

---

### 3. K·∫æ HO·∫†CH TH·ª∞C HI·ªÜN (4-Week Agile Sprint)

#### üìÖ Sprint 1: The Foundation - H·∫° T·∫ßng Container
* **M·ª•c ti√™u:** D·ª±ng c·ª•m Cluster ·∫£o. L·ªánh `docker-compose up` ch·∫°y m∆∞·ª£t, Kafka v√† MinIO xanh ƒë√®n.
* **C√¥ng vi·ªác:**
    1.  C√†i ƒë·∫∑t Docker Desktop.
    2.  Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng:
        * T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c.
        * C·∫•u h√¨nh Git.
    3.  Vi·∫øt `docker-compose.yaml`:
        * `portainer`: Monitoring & Container Management.
        * `kafka`: Image `bitnami/kafka`, KRaft mode (No Zookeeper).
        * `minio`: Image `minio/minio`, t·∫°o bucket `yagi-data`.
        * `spark-master` & `spark-worker`: Image `bitnami/spark`, gi·ªõi h·∫°n RAM Worker 2GB.
    4.  Ki·ªÉm tra k·∫øt n·ªëi c√°c service (Smoke Test).

#### üìÖ Sprint 2: The Storm Replay - D√≤ng Ch·∫£y D·ªØ Li·ªáu
* **M·ª•c ti√™u:** T√°i hi·ªán c∆°n b√£o Yagi tr√™n h·ªá th·ªëng. D·ªØ li·ªáu t·ª´ CSV ch·∫£y v√†o Kafka v√† n·∫±m an to√†n trong Delta Lake.
* **C√¥ng vi·ªác:**
    1.  X·ª≠ l√Ω file CSV `Hai phong_Yagi.csv`: L√†m s·∫°ch, chu·∫©n h√≥a timestamp.
    2.  Code `yagi_producer.py`: ƒê·ªçc CSV, gi·∫£ l·∫≠p delay, b·∫Øn v√†o Kafka topic `weather-stream`.
    3.  Code `spark_ingestion.py`:
        * ƒê·ªçc Kafka topic `weather-stream`.
        * Ghi xu·ªëng MinIO bucket `yagi-data` ƒë·ªãnh d·∫°ng **Delta Lake**.
    4.  Ki·ªÉm tra: Th·∫•y file Parquet xu·∫•t hi·ªán li√™n t·ª•c trong MinIO console.

#### üìÖ Sprint 3: The Intelligence - MLOps Logic
* **M·ª•c ti√™u:** H·ªá th·ªëng c√≥ "n√£o". D·ª± b√°o ƒë∆∞·ª£c xu h∆∞·ªõng b√£o.
* **C√¥ng vi·ªác:**
    1.  Train Model (Colab):
        * S·ª≠ d·ª•ng d·ªØ li·ªáu Yagi (ho·∫∑c d·ªØ li·ªáu l·ªãch s·ª≠ t∆∞∆°ng t·ª±).
        * Train model `StormPrediction` (Regression d·ª± b√°o s·ª©c gi√≥ ho·∫∑c Classification r·ªßi ro).
    2.  Export Model: L∆∞u model d·∫°ng `.zip` ho·∫∑c `.pkl`.
    3.  Deploy (Local): Vi·∫øt service `predictor` trong Docker.
        * Subscribe Kafka `weather-stream`.
        * Predict: N·∫øu gi√≥ > 60km/h -> G·ª≠i c·∫£nh b√°o v√†o Kafka topic `alerts`.

#### üìÖ Sprint 4: The Interface & Resilience - Giao Di·ªán & Ch·ªãu L·ªói
* **M·ª•c ti√™u:** Dashboard ƒë·∫πp, Demo kh·∫£ nƒÉng t·ª± ph·ª•c h·ªìi.
* **C√¥ng vi·ªác:**
    1.  Code Dashboard Streamlit:
        * Chart 1: T·ªëc ƒë·ªô gi√≥ th·ª±c t·∫ø (Real-time).
        * Chart 2: √Åp su·∫•t kh√≠ quy·ªÉn.
        * V√πng c·∫£nh b√°o ƒë·ªè khi b√£o v·ªÅ.
    2.  T√≠ch h·ª£p Telegram API b√°o tin.
    3.  **Chaos Engineering Test:**
        * K·ªãch b·∫£n: ƒêang b√£o to -> T·∫Øt container `predictor` -> H·ªá th·ªëng t·ª± restart container -> Dashboard ti·∫øp t·ª•c ch·∫°y, kh√¥ng m·∫•t d·ªØ li·ªáu.

---

### 4. TECH STACK (T·ªëi ∆∞u 16GB RAM)

| Th√†nh ph·∫ßn | C√¥ng ngh·ªá | Ghi ch√∫ |
| :--- | :--- | :--- |
| **Ng√¥n ng·ªØ** | Python 3.9+ | PySpark, Streamlit, Pandas |
| **Message Queue** | **Apache Kafka** | **KRaft Mode** (No Zookeeper - Ti·∫øt ki·ªám RAM) |
| **Big Data Engine** | **Apache Spark** | Streaming & SQL |
| **Storage** | **MinIO** | S3 Compatible |
| **Data Format** | **Delta Lake** | ACID, Time Travel |
| **DevOps** | Docker Compose | Qu·∫£n l√Ω h·∫° t·∫ßng |
| **Monitoring** | **Portainer** | Qu·∫£n l√Ω container tr·ª±c quan |
| **Training** | Google Colab | T·∫≠n d·ª•ng Cloud GPU |
